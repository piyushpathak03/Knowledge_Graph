{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Knowledge Graphs.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOneVRkt4l5n+Y94WGiY7kL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GfKGTDgEWV-2"},"outputs":[],"source":["import re\n","import pandas as pd\n","import bs4\n","import requests\n","import spacy\n","from spacy import displacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","from spacy.matcher import Matcher \n","from spacy.tokens import Span \n","\n","import networkx as nx\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","pd.set_option('display.max_colwidth', 200)\n","%matplotlib inline"]},{"cell_type":"code","source":["# import wikipedia sentences\n","candidate_sentences = pd.read_csv(\"wiki_sentences_v2.csv\")\n","print(candidate_sentences.shape)\n","candidate_sentences.head(5)"],"metadata":{"id":"dHkN3ZMPWhoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Let’s check the subject and object of one of these sentences. Ideally, there should be one subject and one object in the sentence:\n","doc = nlp(\"later, a woman’s scream is heard in the distance.\")\n","\n","for tok in doc:\n","  print(tok.text, \"...\", tok.dep_)"],"metadata":{"id":"1vlPD5coWkWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##main idea is to go through a sentence and extract the subject and the object as and when they are encountered. \n","\n","def get_entities(sent):\n","  ## chunk 1\n","  ent1 = \"\"\n","  ent2 = \"\"\n","\n","  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n","  prv_tok_text = \"\"   # previous token in the sentence\n","\n","  prefix = \"\"\n","  modifier = \"\"\n","\n","  #############################################################\n","  \n","  for tok in nlp(sent):\n","    ## chunk 2\n","    # if token is a punctuation mark then move on to the next token\n","    if tok.dep_ != \"punct\":\n","      # check: token is a compound word or not\n","      if tok.dep_ == \"compound\":\n","        prefix = tok.text\n","        # if the previous word was also a 'compound' then add the current word to it\n","        if prv_tok_dep == \"compound\":\n","          prefix = prv_tok_text + \" \"+ tok.text\n","      \n","      # check: token is a modifier or not\n","      if tok.dep_.endswith(\"mod\") == True:\n","        modifier = tok.text\n","        # if the previous word was also a 'compound' then add the current word to it\n","        if prv_tok_dep == \"compound\":\n","          modifier = prv_tok_text + \" \"+ tok.text\n","      \n","      ## chunk 3\n","      if tok.dep_.find(\"subj\") == True:\n","        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n","        prefix = \"\"\n","        modifier = \"\"\n","        prv_tok_dep = \"\"\n","        prv_tok_text = \"\"      \n","\n","      ## chunk 4\n","      if tok.dep_.find(\"obj\") == True:\n","        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n","        \n","      ## chunk 5  \n","      # update variables\n","      prv_tok_dep = tok.dep_\n","      prv_tok_text = tok.text\n","  #############################################################\n","\n","  return [ent1.strip(), ent2.strip()]"],"metadata":{"id":"2ribyZBeWxcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_entities(\"the film had 200 patents\")"],"metadata":{"id":"iV0l-F7JXWXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["entity_pairs = []\n","\n","for i in tqdm(candidate_sentences[\"sentence\"]):\n","  entity_pairs.append(get_entities(i))"],"metadata":{"id":"P_W6Q8N-XpOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["entity_pairs[10:20]"],"metadata":{"id":"Ay-XFNSsYbNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_relation(sent):\n","\n","  doc = nlp(sent)\n","\n","  # Matcher class object \n","  matcher = Matcher(nlp.vocab)\n","\n","  #define the pattern \n","  pattern = [{'DEP':'ROOT'}, \n","            {'DEP':'prep','OP':\"?\"},\n","            {'DEP':'agent','OP':\"?\"},  \n","            {'POS':'ADJ','OP':\"?\"}] \n","\n","  matcher.add(\"matching_1\", None, pattern) \n","\n","  matches = matcher(doc)\n","  k = len(matches) - 1\n","\n","  span = doc[matches[k][1]:matches[k][2]] \n","\n","  return(span.text)"],"metadata":{"id":"nkFuCVGvYfPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_relation(\"John completed the task\")"],"metadata":{"id":"Ew-WUmrsYovX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["relations = [get_relation(i) for i in tqdm(candidate_sentences['sentence'])]"],"metadata":{"id":"I9mKmj92YsBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.Series(relations).value_counts()[:50]"],"metadata":{"id":"qnFEJ014Yv6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract subject\n","source = [i[0] for i in entity_pairs]\n","\n","# extract object\n","target = [i[1] for i in entity_pairs]\n","\n","kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})\n","kg_df"],"metadata":{"id":"eyky6NBmYyJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a directed-graph from a dataframe\n","G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", \n","                          edge_attr=True, create_using=nx.MultiDiGraph())\n","G"],"metadata":{"id":"86TYdJASY8lI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12,12))\n","\n","pos = nx.spring_layout(G)\n","nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)\n","plt.show()"],"metadata":{"id":"x6dtKtypZD7P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G=nx.from_pandas_edgelist(kg_df[kg_df['edge']==\"composed by\"], \"source\", \"target\", \n","                          edge_attr=True, create_using=nx.MultiDiGraph())\n","\n","plt.figure(figsize=(12,12))\n","pos = nx.spring_layout(G, k = 0.5) # k regulates the distance between nodes\n","nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\n","plt.show()"],"metadata":{"id":"9iwjMyioZGd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G=nx.from_pandas_edgelist(kg_df[kg_df['edge']==\"written by\"], \"source\", \"target\", \n","                          edge_attr=True, create_using=nx.MultiDiGraph())\n","\n","plt.figure(figsize=(12,12))\n","pos = nx.spring_layout(G, k = 0.5)\n","nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\n","plt.show()"],"metadata":{"id":"FLr1_IpUZM7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"M3pNkzzCZT9u"},"execution_count":null,"outputs":[]}]}